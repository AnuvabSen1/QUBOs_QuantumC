# -*- coding: utf-8 -*-
"""OpenQAOA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CKddiAA5_-vHTjs1WKt5pPCve3j_6xMG

#Solving QUBOs with Qiskit-Optimization QAOA

### **Introduction**

OpenQAOA is multi-backend SDK used to easily implement QAOA circuits. It provides simple yet very detailed implementations of QAOA circuits that can not only run on IBMQ devices and simulators but also Rigetti Cloud Services, Amazon Braket, Microsoft Azure. The parent company of OpenQAOA also provide usage of their own custom simulators. Note that for resources like Rigetti, Braket, and Azure, the devices are only available with a subscription to their quantum services. Similar to Qiskit-Optimization, OpenQAOA can be used to generate custom problem QUBOs however these capabilities are neglected so the user can easily implement their own custom algorithms.

OpenQAOA is one of the best QAOA circuit SDKs availability not only because of the large range of applicable devices, but also the level of customizability and relevancy to ongoing research. OpenQAOA not only offers standard QAOA circuits but also recursive implementations RQAOA, as well as varied parametrization, initialization, and mixing strategies. OpenQAOA also offers a larger selection of optimizers than Qiskit-Optimization that are classified to three main categories: gradient-based, gradient-free, and shot-adaptive. Finally it is easy to plot data like optimization pathways or bitstring distributions using OpenQAOA.

Although OpenQAOA offers more optimizers than Qiskit-Optimization, however there list is still limited, and it is difficult to use custom optimizers. Furthermore similar to Qiskit-Optimization although you can adjust the circuit properties, you cannot directly modify the circuits also hindering the level of control.
"""

# need python version 3.8 - 3.10
try:
  import google.colab
  IN_COLAB = True
except:
  IN_COLAB = False

if IN_COLAB:
  !pip install -q qiskit==0.39.2
  !pip install -q qiskit-optimization==0.5.0
  !pip install -q openqaoa==0.2.5
  print("All Packages Installed!")

# base qiskit imports
from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute
from qiskit_optimization.translators import from_docplex_mp
from qiskit_optimization import QuadraticProgram
from qiskit.visualization import plot_histogram
from qiskit_optimization.converters import QuadraticProgramToQubo

# Misc. Imports
import time
import numpy as np
import networkx as nx
import matplotlib.pyplot as plt

# Import the libraries needed to employ the QAOA quantum algorithm using OpenQAOA
from openqaoa import QAOA
from openqaoa.backends import create_device
from openqaoa.problems import NumberPartition, MaximumCut
from openqaoa.utilities import plot_graph

# method to convert a docplex model to a qubo problem
from docplex.mp.model import Model
from openqaoa.problems.converters import FromDocplex2IsingModel

"""### **Example 1 - Number Partitioning Problem**

Using OpenQAOA NumberPartition feature to generate a random array. This array is converted to the QUBO in the following step.
"""

prob = NumberPartition.random_instance(n_numbers=4)
qubo = prob.qubo
test = qubo.asdict()['problem_instance']['numbers']
arr = test
print(arr)
n = len(arr)
c = sum(arr)

"""**Number Partitioning Models**

Given an array of $n$ integers $[a_{1}, a_{2}, a_{3} ... a_{n}]$, the corresponding Ising Hamiltonian is:

$$H=(\sum_{i=1}^{n}a_{i}s_{i})^2$$

Where $s_{i} \in \{-1,1\}$ is the Ising spin variable.

Similarly the corresponding QUBO Model is:

$$Q=(\sum_{i=1}^{n}a_{i}-2\sum_{i=1}^{n}a_{i}x_{i})^{2}$$
or
$$Q=(c-2\sum_{i=1}^{n}a_{i}x_{i})^{2}$$

Where $c=\sum_{i=1}^{n}a_{i}$ and $x_{i} \in \{0, 1\}$ is a binary quadratic variable.
"""

model = Model()
x = model.binary_var_list(n)
H = (c - 2*sum(arr[i]*x[i] for i in range(n)))**2
model.minimize(H)

"""The QUBO Model is then converted to an Ising model to solve using QAOA."""

# Converting the Docplex model into its qubo representation
qubo = FromDocplex2IsingModel(model)

# Ising encoding of the QUBO problem
npp_ising = qubo.ising_model

"""**Solving the QUBO**

We then set multiple characteristics for the QAOA circuits, such as device, circuit properties, backend properties, and optimizer. In the example below, the backend is "qiskit.qasm_simulator", the number of diffuser and mixer layers is $2$, the number of shots is $1000$, and the optimizer is Cobyla with a maximum of $250$ iterations. Cobyla is one of the gradient independent optimizers provided by OpenQAOA.
"""

# initialize model
q = QAOA()

# device
q.set_device(create_device('local', 'qiskit.qasm_simulator'))

# circuit properties
q.set_circuit_properties(p=2, param_type='standard', init_type='rand', mixer_hamiltonian='x')

# backend properties
q.set_backend_properties(n_shots = 1000)

# set optimizer and properties
q.set_classical_optimizer(maxiter=250, method='cobyla')

q.compile(npp_ising)

#import time
start_time = time.time()
q.optimize()
end_time = time.time()
elapsed_time = end_time - start_time

"""**Plotting the Results**

The resulting bitstrings are plotted in a histograms below.

Bitstrings with higher probabilites correspond to better solutions for the number partitioning problem.
"""

q.result.plot_probabilities(5)

"""**Optimization Plot**

The bitstrings optimization pathway is shown below.

As shown, the bitstring cost starts off large however after more iterations of Cobyla, the corresponding cost decreases.
"""

q.result.plot_cost()

# Converting the output binary variables to produce a valid output
def NPP_measure(solution, print=None):
    P1 = []
    P2 = []
    for i in range(len(solution)):
        if solution[i] == '0':
            P1.append(arr[i])
        else:
            P2.append(arr[i])
    sum1 = sum(P1[i] for i in range(len(P1)))
    sum2 = sum(P2[i] for i in range(len(P2)))
    if print:
      print("Partition 1:")
      print(P1)
      print('Sum: ' + str(sum1))
      print("Partition 2:")
      print(P2)
      print('Sum: ' + str(sum2))
    return abs(sum1 - sum2)

solutions = q.result.most_probable_states['solutions_bitstrings']
print("Number of Solutions: " + str(len(solutions)))
sorted_solution = sorted(solutions, key=NPP_measure)
print("Optimization Time: " + str(elapsed_time))
NPP_measure(sorted_solution[0], print)

"""### **Example 2 - Max-Cut Problem**

Using OpenQAOA MaxCut feature to generate a random graph. This graph is converted to the QUBO in the following step.
"""

def draw_graph(G, colors, pos):
    default_axes = plt.axes()
    nx.draw_networkx(G, node_color=colors, node_size=600, alpha=0.8, ax=default_axes, pos=pos)
    edge_labels = nx.get_edge_attributes(G, "weight")

G = nx.generators.fast_gnp_random_graph(n=6, p=0.5)
n = 6
colors = ["r" for node in G.nodes()]
pos = nx.spring_layout(G)
draw_graph(G, colors, pos)

"""**Max-Cut Models**

Given an undirected unweighted Graph $G$ with vertex set $V$ and edge set $E$ with edges $(i, j)$ the corresponding Ising Hamiltonian is:

$$H=\sum_{(i, j) \in E}\frac{1-s_{i}s_{j}}{2}$$

Where $s_{i} \in \{-1,1\}$ is the Ising spin variable.

The corresponding QUBO Model is:

$$Q=\sum_{(i, j)\in E}(x_{i}+x_{j}-2x_{i}x_{j})$$

Where $x_{i} \in \{0, 1\}$ is a binary quadratic variable.
"""

model = Model()
x = model.binary_var_list(n)
H = sum(2*x[e[0]]*x[e[1]] - x[e[0]] - x[e[1]] for e in G.edges)
model.minimize(H)

# Converting the Docplex model into its qubo representation
qubo = FromDocplex2IsingModel(model)

# Ising encoding of the QUBO problem
maxcut_ising = qubo.ising_model

"""**Solving the QUBO**

We then set multiple characteristics for the QAOA circuits, such as device, circuit properties, backend properties, and optimizer. In the example below, the backend is "vectorized", the number of diffuser and mixer layers is $2$, the number of shots is $1000$, and the optimizer is Vanilla Gradient Descent with a maximum of $250$ iterations. The gradient was computed using the finite difference method.
"""

# initialize model
q = QAOA()

# device
q.set_device(create_device('local', 'vectorized'))

# circuit properties
q.set_circuit_properties(p=2, param_type='standard', init_type='rand', mixer_hamiltonian='x')

# backend properties
q.set_backend_properties(n_shots = 1000)

# set optimizer and properties
q.set_classical_optimizer(method='vgd', jac="finite_difference")

q.compile(maxcut_ising)

#import time
start_time = time.time()
q.optimize()
end_time = time.time()
elapsed_time = end_time - start_time

"""**Plotting the Results**

The resulting bitstrings are plotted in a histograms below.

Bitstrings with higher probabilites correspond to better solutions for the Max-Cut problem.
"""

q.result.plot_probabilities()

"""**Optimization Plot**

The bitstrings optimization pathway is shown below.

As shown, the bitstring cost starts off large however after more iterations of VGD, the corresponding cost decreases. Note that since VGD uses the gradient, the descent is smoother than gradient-free optimization techniques.
"""

q.result.plot_cost()

# Converting the output binary variables to produce a valid output
def MaxCut_measure(solution, print=None):
  cut_size = 0
  for u, v in G.edges():
      if solution[u] != solution[v]:
          cut_size -= 1
  colors = ["r" if solution[i] == "0" else "c" for i in range(len(solution))]
  if print:
    draw_graph(G, colors, pos)
  return -cut_size

solutions = q.result.most_probable_states['solutions_bitstrings']
print("Number of Solutions: " + str(len(solutions)))
sorted_solution = sorted(solutions, key=MaxCut_measure)
print("Optimization Time: " + str(elapsed_time))
MaxCut_measure(sorted_solution[0], print)

"""### **Example 3 - Minimum Vertex Cover**"""

G = nx.generators.fast_gnp_random_graph(n=6, p=0.5)
n=6
colors = ["r" for node in G.nodes()]
pos = nx.spring_layout(G)
draw_graph(G, colors, pos)

"""**Minimum Vertex Cover Models**

Given an undirected unweighted Graph $G$ with vertex set $V$ with vertices $i$ and edge set $E$ with edges $(i, j)$ the corresponding Ising Hamiltonian is:

$$H=P\sum_{(i, j) \in E}(1-s_{i})(1-s_{j}) + \sum_{i \in V}s_{i}$$

Where $s_{i} \in \{-1,1\}$ is the Ising spin variable and $P$ is the penalty coefficient.

The corresponding QUBO Model is:

$$Q=\sum_{i \in V}x_{i} + P(\sum_{(i, j) \in E}(1-x_{i}-x_{j}+x_{i}x_{j}))$$

Where $x_{i} \in \{0, 1\}$ is a binary quadratic variable.

Note in the example $P$ was chosen through trial-and-error although there exists rigorous mathematical processes
"""

model = Model()
x = model.binary_var_list(n)
P = 1
H = sum(x[i] for i in range(n)) + P*sum(1 - x[e[0]] - x[e[1]] + x[e[0]]*x[e[1]] for e in G.edges)
model.minimize(H)

# Converting the Docplex model into its qubo representation
qubo = FromDocplex2IsingModel(model)

# Ising encoding of the QUBO problem
mvc_ising = qubo.ising_model

"""**Solving the QUBO**

We then set multiple characteristics for the QAOA circuits, such as device, circuit properties, backend properties, and optimizer. In the example below, the backend is "qiskit.shot_simulator", the number of diffuser and mixer layers is $2$, the number of shots is $1000$, and the optimizer is CANS (Coupled Adaptive Shots) with a maximum of $250$ iterations. This is an example of a shot-adaptive optimizer. Shot-adaptive optimizers take advantage of quantum computing to improve optimization. They do this by computing the gradient using varying numbers of shots which is chosen via some selection strategy.
"""

# initialize model
q = QAOA()

# device
q.set_device(create_device('local', 'qiskit.shot_simulator'))

# backend properties
q.set_backend_properties(n_shots = 1000)

# set optimizer and properties
q.set_classical_optimizer(method='cans', jac="param_shift", maxiter=100, optimizer_options=dict(stepsize=0.001, mu=0.95, b=0.001, n_shots_min=10, n_shots_max=100, n_shots_budget=50000))

q.compile(mvc_ising)

#import time
start_time = time.time()
q.optimize()
end_time = time.time()
elapsed_time = end_time - start_time

"""**Plotting the Results**

The resulting bitstrings are plotted in a histograms below.

Bitstrings with higher probabilites correspond to better solutions for the Minimum Vertex Cover problem.
"""

q.result.plot_probabilities()

"""**Optimization Plot**

The bitstrings optimization pathway is shown below.

As shown, the bitstring cost starts off large however after more iterations of CANS, the corresponding cost decreases. Note the optimization path is not as clear as with the previous optimizers.
"""

q.result.plot_cost()

# Converting the output binary variables to produce a valid output
def MVC_measure(solution, print=None):
  marked_edges = 0
  for u, v in G.edges():
    if solution[u] == "1" or solution[v] == "1":
      marked_edges -= 1
  num_marked = 0
  for i in range(len(solution)):
    if solution[i] == "1":
      num_marked += 1
  colors = ["r" if solution[i] == "0" else "c" for i in range(len(solution))]
  if print:
    draw_graph(G, colors, pos)
  return P*marked_edges+num_marked

solutions = q.result.most_probable_states['solutions_bitstrings']
print("Number of Solutions: " + str(len(solutions)))
sorted_solution = sorted(solutions, key=MVC_measure)
print("Optimization Time: " + str(elapsed_time))
MVC_measure(sorted_solution[0], print)